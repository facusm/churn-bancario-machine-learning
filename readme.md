# ğŸ“‰ğŸ—“ï¸ğŸ’° PredicciÃ³n de churn â€” Clientes Paquete VIP (Banca) | LightGBM + ValidaciÃ³n temporal + OptimizaciÃ³n de Ganancia

Proyecto end-to-end para **predecir churn** de clientes asociados a un **paquete VIP** en un banco, con foco en **maximizar retorno econÃ³mico** de una campaÃ±a de retenciÃ³n.

En lugar de optimizar mÃ©tricas genÃ©ricas (AUC/F1), el sistema prioriza una **funciÃ³n de ganancia de negocio**, y produce como salida un **ranking** de clientes junto con un **corte Ã³ptimo (top-N)** de clientes a contactar.

---

## ğŸ¯ QuÃ© resuelve (visiÃ³n de negocio)

**Problema:** dado un universo mensual de clientes VIP, identificar a quiÃ©nes conviene incentivar para evitar baja.  
**DecisiÃ³n:** contactar a un subconjunto limitado (capacidad de campaÃ±a).  
**Objetivo:** maximizar ganancia esperada considerando:
- âœ… beneficio por retener un cliente de alto riesgo,
- ğŸ’¸ costo por contactar a un cliente que no iba a darse de baja.

**Salida final:** archivo de scoring para campaÃ±a con los `N` clientes priorizados.

---

## ğŸ§  Enfoque de modelado

1. **Modelo de ranking**: LightGBM predice probabilidad de churn y ordena clientes.
2. **OptimizaciÃ³n orientada a ganancia**: se evalÃºa el retorno econÃ³mico al contactar a los top-N.
3. **SelecciÃ³n robusta de N**: se elige un `N` que maximiza ganancia de forma **estable** (evitando decisiones â€œfinasâ€ que cambian mucho ante pequeÃ±as variaciones).
4. **ValidaciÃ³n temporal**: splits por mes para simular condiciones reales (entrenar en pasado, evaluar en meses posteriores), evitando leakage.

---

## ğŸ§© Features y calidad de datos

Feature engineering diseÃ±ado para series temporales por cliente (mensual):

- **DetecciÃ³n de datos anÃ³malos por mes**: identifica variables â€œrotasâ€ (por ejemplo, todo en cero para todos los clientes) y las marca como faltantes.
- **NormalizaciÃ³n robusta de variables monetarias por mes**: corrige cambios de escala / drift usando transformaciones robustas por perÃ­odo.
- **Features temporales**:
  - lags,
  - deltas (cambios vs meses anteriores),
  - tendencia (pendiente) en ventanas.
- **Ratios** entre variables relevantes (ej. consumos vs lÃ­mites) para capturar comportamiento relativo.

---

## ğŸ§ª Reproducibilidad y experimentaciÃ³n

- **GestiÃ³n de experimentos**: cada corrida genera un identificador Ãºnico y guarda:
  - logs,
  - base de Optuna,
  - modelos entrenados,
  - predicciones finales.
- **ReutilizaciÃ³n de modelos**: si un modelo ya existe para una semilla/configuraciÃ³n, se carga sin reentrenar.
- **Ensembles multi-semilla**: reduce varianza y mejora estabilidad del ranking.

---

## ğŸ—‚ï¸ Estructura del repositorio

```text
churn_bancario_machine_learning/
â”œâ”€ config/                     # parÃ¡metros, paths, splits temporales, seeds, ganancia
â”œâ”€ src/                        # carga/splits, optimizaciÃ³n, entrenamiento, predicciÃ³n
â”œâ”€ target_feature_engineering/ # creaciÃ³n de target + feature engineering
â”œâ”€ main.py                     # pipeline completo (train â†’ validaciones â†’ test â†’ CSV final)
â”œâ”€ requirements.txt
â””â”€ crear_venv.sh
```


### ğŸ§± MÃ³dulos principales

- `target_feature_engineering/crear_target.ipynb`  
  Construye el target (clases de churn) a partir de la historia temporal del cliente.

- `target_feature_engineering/run_fe.py` + `features.py`  
  Ejecuta feature engineering y genera el dataset final en Parquet.

- `src/data_load_preparation.py`  
  Carga eficiente, crea targets/pesos y arma splits por meses.

- `src/optuna_optimization.py`  
  Optimiza hiperparÃ¡metros maximizando ganancia en validaciÃ³n temporal.

- `src/training_predict.py`  
  Entrena ensemble final, rankea y aplica top-N para generar el output.

- `main.py`  
  Orquesta todo el pipeline y genera el CSV final de campaÃ±a.

---

## ğŸš€ CÃ³mo correr el proyecto

Seguir estos pasos en orden para configurar el entorno y ejecutar el pipeline de datos.

### 1) ConfiguraciÃ³n del Entorno

Primero, crear y activar el entorno virtual, e instalar las dependencias necesarias:

```bash
bash crear_venv.sh
source venv/bin/activate
pip install -r requirements.txt
```

### 2) Generar dataset con target (si no existe)

Ejecutar el notebook:

- `target_feature_engineering/crear_target.ipynb`

Este paso genera el dataset con la columna `clase_ternaria` y lo guarda en el path configurado en `DATASET_TARGETS_CREADOS_PATH` (ver `config/config.py`).


### 3) Generar features (Parquet)

```bash
python -m target_feature_engineering.run_fe
```
Este paso lee el dataset con target y produce el dataset final con feature engineering en formato Parquet (guardado en `FE_PATH`).

### 4) Entrenar + seleccionar top-N + exportar archivo final

```bash
python main.py
```

Outputs principales (se crean dentro del directorio del experimento):

- **Logs**: `.../logs/`
- **Modelos**: `.../modelos_*`
- **PredicciÃ³n final (archivo de campaÃ±a/envÃ­o)**: `.../resultados_prediccion/envio_<experimento>_N<k>.csv`
